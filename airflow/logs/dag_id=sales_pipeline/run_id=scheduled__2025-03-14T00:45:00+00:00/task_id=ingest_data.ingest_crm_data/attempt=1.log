[2025-03-14T01:03:54.917+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-03-14T01:03:54.942+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sales_pipeline.ingest_data.ingest_crm_data scheduled__2025-03-14T00:45:00+00:00 [queued]>
[2025-03-14T01:03:54.955+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sales_pipeline.ingest_data.ingest_crm_data scheduled__2025-03-14T00:45:00+00:00 [queued]>
[2025-03-14T01:03:54.956+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 1
[2025-03-14T01:03:54.973+0000] {taskinstance.py:2327} INFO - Executing <Task(PythonOperator): ingest_data.ingest_crm_data> on 2025-03-14 00:45:00+00:00
[2025-03-14T01:03:54.982+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1967) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-03-14T01:03:54.984+0000] {standard_task_runner.py:63} INFO - Started process 1971 to run task
[2025-03-14T01:03:54.984+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'sales_pipeline', 'ingest_data.ingest_crm_data', 'scheduled__2025-03-14T00:45:00+00:00', '--job-id', '216', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp7yn4n6qd']
[2025-03-14T01:03:54.986+0000] {standard_task_runner.py:91} INFO - Job 216: Subtask ingest_data.ingest_crm_data
[2025-03-14T01:03:55.038+0000] {task_command.py:426} INFO - Running <TaskInstance: sales_pipeline.ingest_data.ingest_crm_data scheduled__2025-03-14T00:45:00+00:00 [running]> on host 2b35ac7f54da
[2025-03-14T01:03:55.146+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Mahmoud' AIRFLOW_CTX_DAG_ID='sales_pipeline' AIRFLOW_CTX_TASK_ID='ingest_data.ingest_crm_data' AIRFLOW_CTX_EXECUTION_DATE='2025-03-14T00:45:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-03-14T00:45:00+00:00'
[2025-03-14T01:03:55.147+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-03-14T01:03:55.248+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108: UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
  warn_incompatible_dep(

[2025-03-14T01:03:55.362+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-14T01:03:55.362+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-14T01:03:55.363+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-14T01:03:56.234+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-14T01:03:56.235+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.3", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-14T01:03:56.236+0000] {pipeline.py:77} INFO - ðŸ“¥ Ingesting CRM data...
[2025-03-14T01:03:56.236+0000] {ingest_data.py:28} ERROR - Error ingesting data from cust_info.csv into crm_cust_info: 'NoneType' object has no attribute 'execute'
[2025-03-14T01:03:56.236+0000] {ingest_data.py:28} ERROR - Error ingesting data from prd_info.csv into crm_prd_info: 'NoneType' object has no attribute 'execute'
[2025-03-14T01:03:56.237+0000] {ingest_data.py:28} ERROR - Error ingesting data from sales_details.csv into crm_sales_details: 'NoneType' object has no attribute 'execute'
[2025-03-14T01:03:56.337+0000] {snowflake_utilz.py:35} INFO - connection is closed
[2025-03-14T01:03:56.337+0000] {connection.py:810} INFO - closed
[2025-03-14T01:03:56.413+0000] {connection.py:816} INFO - No async queries seem to be running, deleting session
[2025-03-14T01:03:56.498+0000] {snowflake_utilz.py:38} INFO - SQLAlchemy engine disposed
[2025-03-14T01:03:56.498+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-03-14T01:03:56.499+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-03-14T01:03:56.510+0000] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=sales_pipeline, task_id=ingest_data.ingest_crm_data, execution_date=20250314T004500, start_date=20250314T010354, end_date=20250314T010356
[2025-03-14T01:03:56.562+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-03-14T01:03:56.626+0000] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-03-14T01:03:56.627+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
