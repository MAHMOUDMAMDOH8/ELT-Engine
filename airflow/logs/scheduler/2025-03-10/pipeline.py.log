[2025-03-10T14:38:12.276+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:38:12.277+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:38:12.278+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:38:12.278+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:38:12.284+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:38:12.282+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:38:12.284+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:38:12.303+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.034 seconds
[2025-03-10T14:38:28.372+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:38:28.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:38:28.374+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:38:28.374+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:38:28.381+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:38:28.380+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:38:28.382+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:38:28.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.035 seconds
[2025-03-10T14:38:58.564+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:38:58.565+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:38:58.567+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:38:58.567+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:38:58.574+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:38:58.572+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:38:58.574+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:38:58.592+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.033 seconds
[2025-03-10T14:39:28.719+0000] {processor.py:161} INFO - Started process (PID=32) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:39:28.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:39:28.722+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:39:28.722+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:39:28.728+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:39:28.727+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:39:28.729+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:39:28.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.034 seconds
[2025-03-10T14:39:58.878+0000] {processor.py:161} INFO - Started process (PID=33) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:39:58.879+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:39:58.881+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:39:58.881+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:39:58.888+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:39:58.887+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:39:58.889+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:39:58.906+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.033 seconds
[2025-03-10T14:40:29.077+0000] {processor.py:161} INFO - Started process (PID=34) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:40:29.078+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:40:29.080+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:40:29.080+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:40:29.086+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:40:29.085+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:40:29.087+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:40:29.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.033 seconds
[2025-03-10T14:40:59.249+0000] {processor.py:161} INFO - Started process (PID=35) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:40:59.250+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:40:59.253+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:40:59.252+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:40:59.261+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:40:59.259+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:40:59.262+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:40:59.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.048 seconds
[2025-03-10T14:41:29.399+0000] {processor.py:161} INFO - Started process (PID=36) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:41:29.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:41:29.402+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:41:29.402+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:41:29.408+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:41:29.406+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:41:29.408+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:41:29.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.032 seconds
[2025-03-10T14:41:59.581+0000] {processor.py:161} INFO - Started process (PID=37) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:41:59.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:41:59.584+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:41:59.584+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:41:59.591+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:41:59.589+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:41:59.591+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:41:59.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.033 seconds
[2025-03-10T14:42:29.736+0000] {processor.py:161} INFO - Started process (PID=38) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:42:29.737+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:42:29.739+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:42:29.739+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:42:29.746+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:42:29.745+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:42:29.747+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:42:29.765+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.034 seconds
[2025-03-10T14:42:59.915+0000] {processor.py:161} INFO - Started process (PID=39) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:42:59.916+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:42:59.918+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:42:59.918+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:42:59.924+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:42:59.923+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:42:59.925+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:42:59.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.033 seconds
[2025-03-10T14:43:30.075+0000] {processor.py:161} INFO - Started process (PID=40) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:43:30.076+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:43:30.078+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:43:30.077+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:43:30.083+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:43:30.082+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:43:30.084+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:43:30.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.032 seconds
[2025-03-10T14:44:00.219+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:44:00.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:44:00.222+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:44:00.221+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:44:00.227+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:44:00.226+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:44:00.227+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:44:00.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.031 seconds
[2025-03-10T14:44:30.397+0000] {processor.py:161} INFO - Started process (PID=42) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:44:30.398+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:44:30.400+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:44:30.400+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:44:30.408+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:44:30.407+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:44:30.409+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:44:30.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.037 seconds
[2025-03-10T14:45:00.548+0000] {processor.py:161} INFO - Started process (PID=43) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:45:00.549+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:45:00.551+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:45:00.551+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:45:00.558+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:45:00.556+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:45:00.558+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:45:00.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.034 seconds
[2025-03-10T14:45:30.718+0000] {processor.py:161} INFO - Started process (PID=44) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:45:30.719+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:45:30.721+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:45:30.721+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:45:30.727+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:45:30.726+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:45:30.727+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:45:30.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.033 seconds
[2025-03-10T14:46:00.872+0000] {processor.py:161} INFO - Started process (PID=45) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:46:00.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:46:00.875+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:46:00.875+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:46:00.880+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:46:00.879+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:46:00.881+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:46:00.899+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.033 seconds
[2025-03-10T14:46:31.031+0000] {processor.py:161} INFO - Started process (PID=46) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:46:31.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:46:31.034+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:46:31.034+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:46:31.041+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:46:31.039+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:46:31.042+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:46:31.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.045 seconds
[2025-03-10T14:47:01.200+0000] {processor.py:161} INFO - Started process (PID=47) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:47:01.201+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:47:01.203+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:47:01.203+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:47:01.209+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:47:01.208+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:47:01.210+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:47:01.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.033 seconds
[2025-03-10T14:47:31.361+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:47:31.362+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:47:31.364+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:47:31.364+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:47:31.370+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:47:31.369+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:47:31.371+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:47:31.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.034 seconds
[2025-03-10T14:48:01.541+0000] {processor.py:161} INFO - Started process (PID=49) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:48:01.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:48:01.545+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:48:01.544+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:48:01.553+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:48:01.552+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:48:01.553+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:48:01.571+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.036 seconds
[2025-03-10T14:48:31.715+0000] {processor.py:161} INFO - Started process (PID=50) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:48:31.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:48:31.718+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:48:31.718+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:48:31.724+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:48:31.723+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:48:31.725+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:48:31.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.032 seconds
[2025-03-10T14:49:01.874+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:49:01.875+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:49:01.877+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:49:01.877+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:49:01.884+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:49:01.882+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:49:01.884+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:49:01.902+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.034 seconds
[2025-03-10T14:49:32.035+0000] {processor.py:161} INFO - Started process (PID=52) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:49:32.036+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:49:32.038+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:49:32.038+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:49:32.044+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:49:32.042+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:49:32.044+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:49:32.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.034 seconds
[2025-03-10T14:50:02.209+0000] {processor.py:161} INFO - Started process (PID=53) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:50:02.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:50:02.213+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:50:02.213+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:50:02.220+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:50:02.218+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:50:02.221+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:50:02.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.047 seconds
[2025-03-10T14:50:32.377+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:50:32.378+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:50:32.380+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:50:32.380+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:50:32.385+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:50:32.384+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:50:32.386+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:50:32.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.035 seconds
[2025-03-10T14:51:02.525+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:51:02.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:51:02.528+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:51:02.528+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:51:02.535+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:51:02.533+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:51:02.536+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:51:02.553+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.034 seconds
[2025-03-10T14:51:32.710+0000] {processor.py:161} INFO - Started process (PID=56) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:51:32.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:51:32.712+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:51:32.712+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:51:32.717+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:51:32.716+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:51:32.718+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:51:32.734+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.031 seconds
[2025-03-10T14:52:02.860+0000] {processor.py:161} INFO - Started process (PID=57) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:52:02.860+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:52:02.863+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:52:02.863+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:52:02.870+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:52:02.869+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:52:02.871+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:52:02.890+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.036 seconds
[2025-03-10T14:52:33.035+0000] {processor.py:161} INFO - Started process (PID=58) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:52:33.036+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:52:33.038+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:52:33.037+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:52:33.045+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:52:33.043+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:52:33.045+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:52:33.064+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.034 seconds
[2025-03-10T14:53:03.229+0000] {processor.py:161} INFO - Started process (PID=59) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:53:03.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:53:03.233+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:53:03.232+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:53:03.239+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:53:03.238+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:53:03.240+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:53:03.258+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.035 seconds
[2025-03-10T14:53:33.412+0000] {processor.py:161} INFO - Started process (PID=60) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:53:33.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:53:33.417+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:53:33.416+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:53:33.424+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:53:33.422+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:53:33.424+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:53:33.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.038 seconds
[2025-03-10T14:54:03.585+0000] {processor.py:161} INFO - Started process (PID=61) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:54:03.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:54:03.588+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:54:03.587+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:54:03.593+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:54:03.592+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:54:03.593+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:54:03.613+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.034 seconds
[2025-03-10T14:54:33.739+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:54:33.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:54:33.742+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:54:33.742+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:54:33.749+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:54:33.747+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:54:33.749+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:54:33.767+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.034 seconds
[2025-03-10T14:55:03.909+0000] {processor.py:161} INFO - Started process (PID=63) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:55:03.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:55:03.913+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:55:03.913+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:55:03.918+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:55:03.917+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:55:03.919+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:55:03.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.038 seconds
[2025-03-10T14:55:34.081+0000] {processor.py:161} INFO - Started process (PID=64) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:55:34.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:55:34.084+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:55:34.084+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:55:34.090+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:55:34.089+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:55:34.091+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:55:34.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.033 seconds
[2025-03-10T14:56:04.257+0000] {processor.py:161} INFO - Started process (PID=65) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:56:04.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:56:04.260+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:56:04.260+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:56:04.268+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:56:04.265+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:56:04.269+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:56:04.292+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.044 seconds
[2025-03-10T14:56:34.408+0000] {processor.py:161} INFO - Started process (PID=66) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:56:34.409+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:56:34.411+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:56:34.410+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:56:34.418+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:56:34.416+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:56:34.419+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:56:34.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.040 seconds
[2025-03-10T14:57:04.568+0000] {processor.py:161} INFO - Started process (PID=67) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:57:04.569+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:57:04.571+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:57:04.570+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:57:04.578+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:57:04.576+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:57:04.578+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:57:04.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.034 seconds
[2025-03-10T14:57:34.754+0000] {processor.py:161} INFO - Started process (PID=68) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:57:34.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:57:34.758+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:57:34.757+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:57:34.764+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:57:34.763+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:57:34.765+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:57:34.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.034 seconds
[2025-03-10T14:57:54.855+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:57:54.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:57:54.858+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:57:54.857+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:57:54.864+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:57:54.862+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:57:54.864+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:57:54.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.030 seconds
[2025-03-10T14:58:25.061+0000] {processor.py:161} INFO - Started process (PID=70) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:58:25.062+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:58:25.064+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:58:25.063+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:58:25.070+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:58:25.069+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 2, in <module>
    from Scripts.ingest_data import *
  File "/opt/airflow/dags/Scripts/ingest_data.py", line 1, in <module>
    from snowflake_utilz import *
ModuleNotFoundError: No module named 'snowflake_utilz'
[2025-03-10T14:58:25.071+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:58:25.087+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.032 seconds
[2025-03-10T14:58:55.252+0000] {processor.py:161} INFO - Started process (PID=71) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:58:55.253+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:58:55.255+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:58:55.255+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:58:57.176+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T14:58:57.622+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:58:57.622+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T14:58:57.623+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:58:57.623+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T14:58:57.624+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:58:57.623+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T14:59:00.102+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:00.102+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T14:59:00.103+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:00.102+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 60, in <module>
    Post_conn, Post_engine = postgres_connection(**snowflake_cred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: postgres_connection() got an unexpected keyword argument 'account'
[2025-03-10T14:59:00.104+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:59:00.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 4.871 seconds
[2025-03-10T14:59:11.209+0000] {processor.py:161} INFO - Started process (PID=74) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:59:11.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:59:11.213+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:11.212+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:59:11.766+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T14:59:11.855+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:11.854+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T14:59:11.855+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:11.855+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T14:59:11.856+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:11.855+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T14:59:12.708+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:12.708+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T14:59:12.711+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:12.708+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 60, in <module>
    Post_conn, Post_engine = postgres_connection(**snowflake_cred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: postgres_connection() got an unexpected keyword argument 'account'
[2025-03-10T14:59:12.711+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:59:12.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.527 seconds
[2025-03-10T14:59:42.911+0000] {processor.py:161} INFO - Started process (PID=77) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:59:42.911+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:59:42.913+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:42.913+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:59:43.639+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T14:59:43.733+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:43.733+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T14:59:43.734+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:43.734+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T14:59:43.735+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:43.734+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T14:59:44.599+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:44.599+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T14:59:44.600+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:44.599+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 60, in <module>
    Post_conn, Post_engine = postgres_connection(**snowflake_cred)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: postgres_connection() got an unexpected keyword argument 'account'
[2025-03-10T14:59:44.601+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T14:59:44.621+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.716 seconds
[2025-03-10T14:59:47.511+0000] {processor.py:161} INFO - Started process (PID=80) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T14:59:47.512+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T14:59:47.514+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:47.513+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T14:59:48.105+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T14:59:48.232+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:48.231+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T14:59:48.233+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:48.232+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T14:59:48.234+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:48.233+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T14:59:48.954+0000] {logging_mixin.py:188} INFO - [2025-03-10T14:59:48.954+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:01:07.918+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:01:07.919+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:01:07.921+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:01:07.921+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:01:08.566+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:01:08.724+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:01:08.723+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:01:08.725+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:01:08.724+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:01:08.725+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:01:08.725+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:01:09.738+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:01:09.737+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:02:28.355+0000] {processor.py:161} INFO - Started process (PID=86) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:02:28.356+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:02:28.357+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:02:28.357+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:02:28.921+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:02:29.015+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:02:29.015+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:02:29.016+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:02:29.016+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:02:29.016+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:02:29.016+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:02:30.021+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:02:30.021+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:03:34.677+0000] {processor.py:161} INFO - Started process (PID=89) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:03:34.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:03:34.680+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:03:34.679+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:03:35.502+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:03:35.646+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:03:35.646+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:03:35.646+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:03:35.646+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:03:35.647+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:03:35.647+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:03:36.548+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:03:36.548+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:04:47.025+0000] {processor.py:161} INFO - Started process (PID=92) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:04:47.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:04:47.028+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:04:47.028+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:04:47.570+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:04:47.685+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:04:47.684+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:04:47.685+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:04:47.685+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:04:47.686+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:04:47.686+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:04:48.784+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:04:48.784+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:12:06.248+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:12:06.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:12:06.251+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:12:06.250+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:12:06.731+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:12:06.820+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:12:06.819+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:12:06.820+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:12:06.820+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:12:06.820+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:12:06.820+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:12:08.088+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:12:08.088+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:13:26.778+0000] {processor.py:161} INFO - Started process (PID=32) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:13:26.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:13:26.781+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:13:26.780+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:13:27.292+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:13:27.378+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:13:27.378+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:13:27.379+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:13:27.379+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:13:27.379+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:13:27.379+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:13:28.349+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:13:28.349+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:14:47.313+0000] {processor.py:161} INFO - Started process (PID=35) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:14:47.314+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:14:47.316+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:14:47.315+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:14:47.781+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:14:47.856+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:14:47.855+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:14:47.856+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:14:47.856+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:14:47.856+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:14:47.856+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:14:49.010+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:14:49.010+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:16:07.873+0000] {processor.py:161} INFO - Started process (PID=38) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:16:07.874+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:16:07.876+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:16:07.875+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:16:08.365+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:16:08.443+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:16:08.443+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:16:08.444+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:16:08.444+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:16:08.444+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:16:08.444+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:16:09.386+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:16:09.386+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:17:28.424+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:17:28.425+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:17:28.427+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:17:28.427+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:17:28.938+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:17:29.019+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:17:29.019+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:17:29.020+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:17:29.020+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:17:29.020+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:17:29.020+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:17:30.040+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:17:30.040+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:18:48.911+0000] {processor.py:161} INFO - Started process (PID=44) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:18:48.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:18:48.913+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:18:48.913+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:18:49.386+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:18:49.464+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:18:49.463+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:18:49.464+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:18:49.464+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:18:49.464+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:18:49.464+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:18:50.458+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:18:50.457+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:20:09.462+0000] {processor.py:161} INFO - Started process (PID=47) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:20:09.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:20:09.464+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:20:09.464+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:20:09.940+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:20:10.015+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:20:10.015+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:20:10.016+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:20:10.016+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:20:10.016+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:20:10.016+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:20:10.951+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:20:10.951+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:21:29.989+0000] {processor.py:161} INFO - Started process (PID=50) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:21:29.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:21:29.991+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:21:29.991+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:21:30.502+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:21:30.584+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:21:30.584+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:21:30.584+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:21:30.584+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:21:30.585+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:21:30.585+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:21:31.511+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:21:31.511+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:22:50.542+0000] {processor.py:161} INFO - Started process (PID=53) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:22:50.543+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:22:50.544+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:22:50.544+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:22:51.021+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:22:51.101+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:22:51.101+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:22:51.102+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:22:51.102+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:22:51.102+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:22:51.102+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:22:52.344+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:22:52.344+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:24:11.058+0000] {processor.py:161} INFO - Started process (PID=56) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:24:11.059+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:24:11.061+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:24:11.061+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:24:11.525+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:24:11.600+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:24:11.600+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:24:11.601+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:24:11.601+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:24:11.601+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:24:11.601+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:24:12.577+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:24:12.577+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:25:31.553+0000] {processor.py:161} INFO - Started process (PID=59) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:25:31.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:25:31.558+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:25:31.557+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:25:32.079+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:25:32.158+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:25:32.157+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:25:32.158+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:25:32.158+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:25:32.158+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:25:32.158+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:25:33.091+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:25:33.091+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:26:17.148+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:26:17.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:26:17.150+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:26:17.150+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:26:17.615+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:26:17.689+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:26:17.688+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:26:17.689+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:26:17.689+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:26:17.689+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:26:17.689+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:26:22.796+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:26:22.795+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:27:37.663+0000] {processor.py:161} INFO - Started process (PID=32) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:27:37.664+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:27:37.665+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:27:37.665+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:27:38.137+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:27:38.211+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:27:38.210+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:27:38.211+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:27:38.211+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:27:38.212+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:27:38.211+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:27:39.152+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:27:39.152+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:28:58.142+0000] {processor.py:161} INFO - Started process (PID=35) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:28:58.143+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:28:58.145+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:28:58.144+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:28:58.643+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:28:58.722+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:28:58.721+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:28:58.722+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:28:58.722+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:28:58.723+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:28:58.722+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:28:59.642+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:28:59.642+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T15:30:11.531+0000] {processor.py:161} INFO - Started process (PID=38) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T15:30:11.531+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T15:30:11.533+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:30:11.533+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T15:30:12.129+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T15:30:12.227+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:30:12.227+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T15:30:12.228+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:30:12.228+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T15:30:12.228+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:30:12.228+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T15:30:13.349+0000] {logging_mixin.py:188} INFO - [2025-03-10T15:30:13.349+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:40:44.976+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:40:44.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:40:44.980+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:40:44.979+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:40:46.857+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:40:47.168+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:40:47.168+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:40:47.169+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:40:47.168+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:40:47.169+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:40:47.169+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:40:53.783+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:40:53.782+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:40:53.788+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:40:53.784+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:40:53.821+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:40:53.854+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:40:53.853+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:40:53.889+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:40:53.889+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:15:00+00:00, run_after=2025-03-10 18:30:00+00:00
[2025-03-10T18:40:53.918+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 8.950 seconds
[2025-03-10T18:41:24.092+0000] {processor.py:161} INFO - Started process (PID=37) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:41:24.093+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:41:24.094+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:41:24.094+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:41:24.663+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:41:24.758+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:41:24.758+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:41:24.758+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:41:24.758+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:41:24.759+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:41:24.759+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:41:25.432+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:41:25.432+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:41:25.434+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:41:25.433+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:41:25.440+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:41:25.699+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:41:25.698+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:41:25.721+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:41:25.721+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:30:00+00:00, run_after=2025-03-10 18:45:00+00:00
[2025-03-10T18:41:25.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.653 seconds
[2025-03-10T18:42:39.293+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:42:39.294+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:42:39.296+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:42:39.296+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:42:39.852+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:42:39.945+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:42:39.944+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:42:39.945+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:42:39.945+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:42:39.946+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:42:39.946+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:42:40.911+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:42:40.910+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:42:40.912+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:42:40.912+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:42:40.917+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:42:40.953+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:42:40.953+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:42:40.975+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:42:40.974+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:30:00+00:00, run_after=2025-03-10 18:45:00+00:00
[2025-03-10T18:42:40.991+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.703 seconds
[2025-03-10T18:43:11.164+0000] {processor.py:161} INFO - Started process (PID=32) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:43:11.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:43:11.167+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:43:11.167+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:43:11.868+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:43:12.013+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:43:12.012+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:43:12.014+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:43:12.013+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:43:12.014+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:43:12.014+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:43:12.998+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:43:12.997+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:43:12.999+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:43:12.999+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:43:13.004+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:43:13.024+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:43:13.023+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:43:13.044+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:43:13.044+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:30:00+00:00, run_after=2025-03-10 18:45:00+00:00
[2025-03-10T18:43:13.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.901 seconds
[2025-03-10T18:44:35.121+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:44:35.122+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:44:35.124+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:44:35.123+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:44:35.621+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:44:35.701+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:44:35.701+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:44:35.701+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:44:35.701+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:44:35.702+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:44:35.702+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:44:36.682+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:44:36.681+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:44:36.684+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:44:36.683+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:44:36.689+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:44:36.727+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:44:36.726+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:44:36.750+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:44:36.750+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:30:00+00:00, run_after=2025-03-10 18:45:00+00:00
[2025-03-10T18:44:36.767+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.652 seconds
[2025-03-10T18:46:54.643+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:46:54.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:46:54.646+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:46:54.645+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:46:55.192+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:46:55.281+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:46:55.281+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:46:55.282+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:46:55.281+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:46:55.282+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:46:55.282+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:47:44.962+0000] {processor.py:161} INFO - Started process (PID=28) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:47:44.963+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:47:44.964+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:47:44.964+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:47:45.645+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:47:45.746+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:47:45.745+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:47:45.746+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:47:45.746+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:47:45.747+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:47:45.746+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:47:46.663+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:47:46.663+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:47:46.665+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:47:46.665+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:47:46.671+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:47:46.701+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:47:46.700+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:47:46.725+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:47:46.725+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:47:46.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.790 seconds
[2025-03-10T18:48:16.933+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:48:16.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:48:16.935+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:48:16.935+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:48:17.471+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:48:17.563+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:48:17.562+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:48:17.563+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:48:17.563+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:48:17.564+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:48:17.563+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:48:18.452+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:48:18.451+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:48:18.454+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:48:18.453+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:48:18.460+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:48:18.568+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:48:18.567+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:48:18.589+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:48:18.588+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:48:18.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.679 seconds
[2025-03-10T18:48:48.758+0000] {processor.py:161} INFO - Started process (PID=34) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:48:48.758+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:48:48.760+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:48:48.760+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:48:49.319+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:48:49.407+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:48:49.407+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:48:49.408+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:48:49.408+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:48:49.408+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:48:49.408+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:48:50.270+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:48:50.269+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:48:50.272+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:48:50.271+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:48:50.276+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:48:50.300+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:48:50.300+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:48:50.322+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:48:50.322+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:48:50.339+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.587 seconds
[2025-03-10T18:49:20.478+0000] {processor.py:161} INFO - Started process (PID=37) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:49:20.479+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:49:20.481+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:49:20.480+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:49:21.029+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:49:21.131+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:49:21.130+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:49:21.131+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:49:21.131+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:49:21.131+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:49:21.131+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:49:22.128+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:49:22.128+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:49:22.131+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:49:22.129+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:49:22.139+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:49:22.172+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:49:22.171+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:49:22.197+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:49:22.196+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:49:22.223+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.751 seconds
[2025-03-10T18:49:52.401+0000] {processor.py:161} INFO - Started process (PID=40) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:49:52.401+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:49:52.403+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:49:52.403+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:49:52.885+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:49:52.963+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:49:52.963+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:49:52.964+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:49:52.964+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:49:52.964+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:49:52.964+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:49:53.826+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:49:53.826+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:49:53.828+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:49:53.827+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:49:53.835+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:49:53.936+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:49:53.936+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:49:53.954+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:49:53.954+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:49:53.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.574 seconds
[2025-03-10T18:50:24.144+0000] {processor.py:161} INFO - Started process (PID=43) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:50:24.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:50:24.147+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:50:24.147+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:50:24.644+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:50:24.722+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:50:24.722+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:50:24.723+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:50:24.722+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:50:24.723+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:50:24.723+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:50:25.618+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:50:25.618+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:50:25.620+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:50:25.620+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:50:25.627+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:50:25.647+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:50:25.647+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:50:25.669+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:50:25.668+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:50:25.687+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.548 seconds
[2025-03-10T18:50:55.858+0000] {processor.py:161} INFO - Started process (PID=50) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:50:55.859+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:50:55.861+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:50:55.861+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:50:56.341+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:50:56.418+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:50:56.418+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:50:56.419+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:50:56.419+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:50:56.419+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:50:56.419+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:50:57.287+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:50:57.286+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:50:57.288+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:50:57.287+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:50:57.292+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:50:57.311+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:50:57.311+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:50:57.330+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:50:57.329+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:50:57.343+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.490 seconds
[2025-03-10T18:51:27.425+0000] {processor.py:161} INFO - Started process (PID=53) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:51:27.426+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:51:27.428+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:51:27.428+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:51:27.918+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:51:28.001+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:51:28.001+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:51:28.002+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:51:28.002+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:51:28.002+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:51:28.002+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:51:28.946+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:51:28.945+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:51:28.948+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:51:28.947+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:51:28.956+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:51:28.981+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:51:28.980+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:51:29.006+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:51:29.006+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:51:29.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.607 seconds
[2025-03-10T18:51:59.187+0000] {processor.py:161} INFO - Started process (PID=56) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:51:59.189+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:51:59.190+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:51:59.190+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:51:59.757+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:51:59.875+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:51:59.875+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:51:59.876+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:51:59.875+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:51:59.876+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:51:59.876+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:52:00.921+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:52:00.921+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:52:00.922+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:52:00.922+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:52:00.927+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:52:00.950+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:52:00.949+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:52:00.971+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:52:00.971+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:52:00.987+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.807 seconds
[2025-03-10T18:52:31.149+0000] {processor.py:161} INFO - Started process (PID=63) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:52:31.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:52:31.152+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:52:31.152+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:52:31.656+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:52:31.734+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:52:31.734+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:52:31.735+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:52:31.734+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:52:31.735+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:52:31.735+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:52:32.689+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:52:32.688+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:52:32.691+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:52:32.690+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:52:32.694+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:52:32.716+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:52:32.715+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:52:32.740+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:52:32.740+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:52:32.758+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.615 seconds
[2025-03-10T18:53:02.880+0000] {processor.py:161} INFO - Started process (PID=66) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:53:02.881+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:53:02.883+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:53:02.882+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:53:03.372+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:53:03.452+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:53:03.451+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:53:03.452+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:53:03.452+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:53:03.452+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:53:03.452+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:53:04.337+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:53:04.337+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:53:04.339+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:53:04.338+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:53:04.344+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:53:04.364+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:53:04.363+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:53:04.383+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:53:04.383+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:53:04.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.526 seconds
[2025-03-10T18:53:34.553+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:53:34.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:53:34.556+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:53:34.556+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:53:35.083+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:53:35.170+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:53:35.170+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:53:35.171+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:53:35.171+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:53:35.171+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:53:35.171+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:53:36.094+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:53:36.094+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:53:36.096+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:53:36.095+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:53:36.101+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:53:36.121+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:53:36.121+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:53:36.149+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:53:36.148+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:53:36.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.622 seconds
[2025-03-10T18:54:06.316+0000] {processor.py:161} INFO - Started process (PID=72) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:54:06.317+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:54:06.318+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:54:06.318+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:54:06.789+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:54:06.876+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:54:06.876+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:54:06.877+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:54:06.877+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:54:06.878+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:54:06.878+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:54:07.748+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:54:07.748+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:54:07.750+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:54:07.749+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:54:07.754+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:54:07.776+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:54:07.775+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:54:07.802+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:54:07.802+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:54:07.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.510 seconds
[2025-03-10T18:54:38.004+0000] {processor.py:161} INFO - Started process (PID=75) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:54:38.005+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:54:38.007+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:54:38.007+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:54:38.478+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:54:38.554+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:54:38.554+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:54:38.555+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:54:38.555+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:54:38.555+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:54:38.555+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:54:39.488+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:54:39.488+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:54:39.491+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:54:39.490+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:54:39.499+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:54:39.522+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:54:39.522+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:54:39.545+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:54:39.545+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:54:39.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.579 seconds
[2025-03-10T18:55:07.614+0000] {processor.py:161} INFO - Started process (PID=78) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:55:07.615+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:55:07.617+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:07.617+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:55:08.307+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:55:08.415+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:08.414+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:55:08.415+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:08.415+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:55:08.416+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:08.416+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:55:09.281+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:09.280+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:55:09.283+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:09.282+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:55:09.283+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:09.283+0000] {pipeline.py:74} ERROR - ❌ PostgreSQL connection failed!
[2025-03-10T18:55:09.286+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:09.283+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 75, in <module>
    raise Exception("PostgreSQL connection could not be established.")
Exception: PostgreSQL connection could not be established.
[2025-03-10T18:55:09.287+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:55:09.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.696 seconds
[2025-03-10T18:55:39.466+0000] {processor.py:161} INFO - Started process (PID=81) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:55:39.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:55:39.469+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:39.469+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:55:40.231+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:55:40.352+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:40.352+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:55:40.353+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:40.353+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:55:40.353+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:40.353+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:55:41.427+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:41.427+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:55:41.428+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:41.428+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:55:41.428+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:41.428+0000] {pipeline.py:74} ERROR - ❌ PostgreSQL connection failed!
[2025-03-10T18:55:41.432+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:55:41.452+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:41.451+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:55:41.476+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:55:41.476+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:55:41.493+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 2.033 seconds
[2025-03-10T18:56:11.628+0000] {processor.py:161} INFO - Started process (PID=88) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:56:11.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:56:11.631+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:11.630+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:56:12.103+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:56:12.178+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:12.177+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:56:12.178+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:12.178+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:56:12.178+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:12.178+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:56:13.023+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:13.023+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:56:13.025+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:13.024+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:56:13.025+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:13.025+0000] {pipeline.py:74} ERROR - ❌ PostgreSQL connection failed!
[2025-03-10T18:56:13.033+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:56:13.060+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:13.059+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:56:13.083+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:13.083+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:56:13.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.479 seconds
[2025-03-10T18:56:43.276+0000] {processor.py:161} INFO - Started process (PID=91) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:56:43.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:56:43.307+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:43.307+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:56:43.921+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:56:44.003+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:44.002+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:56:44.003+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:44.003+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:56:44.004+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:44.004+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:56:44.922+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:44.922+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:56:44.926+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:44.925+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:56:44.927+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:44.927+0000] {pipeline.py:74} ERROR - ❌ PostgreSQL connection failed!
[2025-03-10T18:56:44.933+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:56:44.960+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:44.958+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:56:44.981+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:56:44.981+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:56:45.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.763 seconds
[2025-03-10T18:57:15.197+0000] {processor.py:161} INFO - Started process (PID=94) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:57:15.197+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:57:15.199+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:57:15.199+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:57:15.758+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:57:15.858+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:57:15.857+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:57:15.859+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:57:15.859+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:57:15.859+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:57:15.859+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:57:16.750+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:57:16.750+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:57:16.751+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:57:16.751+0000] {snowflake_utilz.py:29} ERROR - Error while connecting to PostgreSQL: (psycopg2.OperationalError) connection to server at "172.23.0.2", port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-03-10T18:57:16.752+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:57:16.752+0000] {pipeline.py:74} ERROR - ❌ PostgreSQL connection failed!
[2025-03-10T18:57:16.757+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:57:16.777+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:57:16.776+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:57:16.802+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:57:16.801+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:57:16.822+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.630 seconds
[2025-03-10T18:57:44.015+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:57:44.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:57:44.018+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:57:44.018+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:57:44.509+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:57:44.589+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:57:44.589+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:57:44.589+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:57:44.589+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:57:44.590+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:57:44.590+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:57:45.524+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:57:45.524+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:57:45.528+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:57:45.549+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:57:45.549+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:57:45.569+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:57:45.569+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:57:45.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.576 seconds
[2025-03-10T18:58:15.759+0000] {processor.py:161} INFO - Started process (PID=100) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:58:15.760+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:58:15.762+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:58:15.761+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:58:16.290+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:58:16.372+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:58:16.372+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:58:16.373+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:58:16.372+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:58:16.373+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:58:16.373+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:58:17.236+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:58:17.235+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:58:17.240+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:58:17.261+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:58:17.260+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:58:17.283+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:58:17.283+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:58:17.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.547 seconds
[2025-03-10T18:58:47.484+0000] {processor.py:161} INFO - Started process (PID=103) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:58:47.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:58:47.486+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:58:47.486+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:58:47.988+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:58:48.062+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:58:48.062+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:58:48.063+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:58:48.063+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:58:48.063+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:58:48.063+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:58:48.976+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:58:48.976+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:58:48.980+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:58:49.001+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:58:49.000+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:58:49.023+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:58:49.023+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:58:49.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.560 seconds
[2025-03-10T18:59:19.218+0000] {processor.py:161} INFO - Started process (PID=106) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:59:19.219+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:59:19.221+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:19.221+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:59:19.739+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:59:19.817+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:19.817+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:59:19.818+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:19.817+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:59:19.818+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:19.818+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:59:20.682+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:20.682+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:59:20.688+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:59:20.714+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:20.713+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:59:20.738+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:20.738+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:59:20.759+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.549 seconds
[2025-03-10T18:59:50.946+0000] {processor.py:161} INFO - Started process (PID=109) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:59:50.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:59:50.949+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:50.949+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:59:51.452+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/options.py:108 UserWarning: You have an incompatible version of 'pyarrow' installed (19.0.1), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
[2025-03-10T18:59:51.528+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:51.528+0000] {connection.py:423} INFO - Snowflake Connector for Python Version: 3.14.0, Python Version: 3.12.2, Platform: Linux-6.11.0-19-generic-x86_64-with-glibc2.36
[2025-03-10T18:59:51.529+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:51.529+0000] {connection.py:1226} INFO - Connecting to GLOBAL Snowflake domain
[2025-03-10T18:59:51.529+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:51.529+0000] {connection.py:1315} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-03-10T18:59:52.491+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:52.490+0000] {snowflake_utilz.py:13} INFO - Connected to snowflake successfully
[2025-03-10T18:59:52.498+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:59:52.524+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:52.523+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:59:52.551+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:52.550+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:59:52.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.629 seconds
[2025-03-10T18:59:54.381+0000] {processor.py:161} INFO - Started process (PID=112) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T18:59:54.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T18:59:54.383+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:54.383+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T18:59:54.828+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T18:59:54.848+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:54.847+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T18:59:54.867+0000] {logging_mixin.py:188} INFO - [2025-03-10T18:59:54.867+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 18:45:00+00:00, run_after=2025-03-10 19:00:00+00:00
[2025-03-10T18:59:54.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.509 seconds
[2025-03-10T19:00:25.083+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:00:25.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:00:25.085+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:00:25.085+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:00:25.527+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:00:25.545+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:00:25.545+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:00:25.564+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:00:25.564+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:00:25.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.501 seconds
[2025-03-10T19:00:35.150+0000] {processor.py:161} INFO - Started process (PID=120) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:00:35.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:00:35.152+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:00:35.152+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:00:35.618+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:00:35.637+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:00:35.636+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:00:35.657+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:00:35.656+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:00:35.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.527 seconds
[2025-03-10T19:01:05.798+0000] {processor.py:161} INFO - Started process (PID=126) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:01:05.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:01:05.801+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:01:05.801+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:01:06.255+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:01:06.276+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:01:06.275+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:01:06.295+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:01:06.295+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:01:06.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.516 seconds
[2025-03-10T19:01:36.460+0000] {processor.py:161} INFO - Started process (PID=128) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:01:36.461+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:01:36.463+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:01:36.463+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:01:36.956+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:01:36.976+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:01:36.975+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:01:36.995+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:01:36.995+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:01:37.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.555 seconds
[2025-03-10T19:02:07.093+0000] {processor.py:161} INFO - Started process (PID=130) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:02:07.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:02:07.095+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:02:07.095+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:02:07.641+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:02:07.669+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:02:07.668+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:02:07.695+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:02:07.694+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:02:07.720+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.633 seconds
[2025-03-10T19:02:37.894+0000] {processor.py:161} INFO - Started process (PID=136) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:02:37.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:02:37.896+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:02:37.896+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:02:38.335+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:02:38.354+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:02:38.353+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:02:38.372+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:02:38.372+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:02:38.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.498 seconds
[2025-03-10T19:03:08.438+0000] {processor.py:161} INFO - Started process (PID=138) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:03:08.438+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:03:08.440+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:03:08.439+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:03:08.964+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:03:08.998+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:03:08.994+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:03:09.030+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:03:09.030+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:03:09.057+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.625 seconds
[2025-03-10T19:03:39.237+0000] {processor.py:161} INFO - Started process (PID=140) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:03:39.238+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:03:39.240+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:03:39.239+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:03:39.722+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:03:39.747+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:03:39.746+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:03:39.766+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:03:39.766+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:03:39.781+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.550 seconds
[2025-03-10T19:04:09.932+0000] {processor.py:161} INFO - Started process (PID=146) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:04:09.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:04:09.935+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:04:09.934+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:04:10.400+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:04:10.420+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:04:10.420+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:04:10.445+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:04:10.444+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:04:10.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.531 seconds
[2025-03-10T19:04:40.619+0000] {processor.py:161} INFO - Started process (PID=148) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:04:40.620+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:04:40.621+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:04:40.621+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:04:41.063+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:04:41.081+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:04:41.081+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:04:41.099+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:04:41.099+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:04:41.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.503 seconds
[2025-03-10T19:05:11.226+0000] {processor.py:161} INFO - Started process (PID=150) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:05:11.226+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:05:11.229+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:05:11.228+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:05:11.714+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:05:11.733+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:05:11.733+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:05:11.756+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:05:11.755+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:05:11.774+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.554 seconds
[2025-03-10T19:05:41.940+0000] {processor.py:161} INFO - Started process (PID=152) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:05:41.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:05:41.942+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:05:41.942+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:05:42.391+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:05:42.412+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:05:42.411+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:05:42.430+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:05:42.429+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:05:42.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.512 seconds
[2025-03-10T19:06:12.545+0000] {processor.py:161} INFO - Started process (PID=154) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:06:12.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:06:12.548+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:06:12.547+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:06:12.998+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:06:13.021+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:06:13.021+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:06:13.041+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:06:13.040+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:06:13.057+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.518 seconds
[2025-03-10T19:06:43.222+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:06:43.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:06:43.225+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:06:43.225+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:06:43.871+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:06:43.903+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:06:43.902+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:06:43.929+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:06:43.929+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:06:43.952+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.735 seconds
[2025-03-10T19:07:13.899+0000] {processor.py:161} INFO - Started process (PID=162) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:07:13.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:07:13.901+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:07:13.901+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:07:14.446+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:07:14.469+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:07:14.468+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:07:14.495+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:07:14.495+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:07:14.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.625 seconds
[2025-03-10T19:07:44.710+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:07:44.711+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:07:44.714+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:07:44.713+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:07:45.220+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:07:45.240+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:07:45.240+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:07:45.268+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:07:45.268+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:07:45.285+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.584 seconds
[2025-03-10T19:08:15.381+0000] {processor.py:161} INFO - Started process (PID=170) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:08:15.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:08:15.384+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:08:15.383+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:08:15.848+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:08:15.872+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:08:15.872+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:08:15.890+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:08:15.889+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:08:15.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.531 seconds
[2025-03-10T19:08:46.080+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:08:46.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:08:46.083+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:08:46.083+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:08:46.540+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:08:46.562+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:08:46.561+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:08:46.583+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:08:46.583+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:08:46.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.524 seconds
[2025-03-10T19:09:16.736+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:09:16.737+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:09:16.741+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:09:16.739+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:09:17.765+0000] {logging_mixin.py:188} WARNING - Exception ignored in: <module 'collections.abc' from '/usr/local/lib/python3.12/collections/abc.py'>
[2025-03-10T19:09:17.765+0000] {logging_mixin.py:188} WARNING - Traceback (most recent call last):
[2025-03-10T19:09:17.766+0000] {logging_mixin.py:188} WARNING -   File "<string>", line 0, in <module>
[2025-03-10T19:09:17.766+0000] {logging_mixin.py:188} WARNING -   File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/manager.py", line 453, in _exit_gracefully
[2025-03-10T19:09:17.767+0000] {logging_mixin.py:188} WARNING -     self.log.debug("Current Stacktrace is: %s", "\n".join(map(str, inspect.stack())))
[2025-03-10T19:09:17.767+0000] {logging_mixin.py:188} WARNING -                                                                    ^^^^^^^^^^^^^^^
[2025-03-10T19:09:17.768+0000] {logging_mixin.py:188} WARNING -   File "/usr/local/lib/python3.12/inspect.py", line 1774, in stack
[2025-03-10T19:09:17.769+0000] {logging_mixin.py:188} WARNING -     return getouterframes(sys._getframe(1), context)
[2025-03-10T19:09:17.770+0000] {logging_mixin.py:188} WARNING -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-03-10T19:09:17.770+0000] {logging_mixin.py:188} WARNING -   File "/usr/local/lib/python3.12/inspect.py", line 1749, in getouterframes
[2025-03-10T19:09:17.771+0000] {logging_mixin.py:188} WARNING -     traceback_info = getframeinfo(frame, context)
[2025-03-10T19:09:17.772+0000] {logging_mixin.py:188} WARNING -                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-03-10T19:09:17.772+0000] {logging_mixin.py:188} WARNING -   File "/usr/local/lib/python3.12/inspect.py", line 1711, in getframeinfo
[2025-03-10T19:09:17.773+0000] {logging_mixin.py:188} WARNING -     lines, lnum = findsource(frame)
[2025-03-10T19:09:17.774+0000] {logging_mixin.py:188} WARNING -                   ^^^^^^^^^^^^^^^^^
[2025-03-10T19:09:17.774+0000] {logging_mixin.py:188} WARNING -   File "/usr/local/lib/python3.12/inspect.py", line 1087, in findsource
[2025-03-10T19:09:17.775+0000] {logging_mixin.py:188} WARNING -     module = getmodule(object, file)
[2025-03-10T19:09:17.776+0000] {logging_mixin.py:188} WARNING -              ^^^^^^^^^^^^^^^^^^^^^^^
[2025-03-10T19:09:17.777+0000] {logging_mixin.py:188} WARNING -   File "/usr/local/lib/python3.12/inspect.py", line 1004, in getmodule
[2025-03-10T19:09:17.778+0000] {logging_mixin.py:188} WARNING -     if ismodule(module) and hasattr(module, '__file__'):
[2025-03-10T19:09:17.778+0000] {logging_mixin.py:188} WARNING -                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2025-03-10T19:09:17.779+0000] {logging_mixin.py:188} WARNING -   File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/manager.py", line 457, in _exit_gracefully
[2025-03-10T19:09:17.780+0000] {logging_mixin.py:188} WARNING -     sys.exit(os.EX_OK)
[2025-03-10T19:09:17.780+0000] {logging_mixin.py:188} WARNING - SystemExit: 0
[2025-03-10T19:09:17.783+0000] {logging_mixin.py:188} WARNING - <frozen importlib._bootstrap>:488 RuntimeWarning: Cython module failed to patch module with custom type
[2025-03-10T19:09:18.416+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:09:18.451+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:09:18.450+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:09:18.485+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:09:18.485+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:09:18.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.791 seconds
[2025-03-10T19:09:35.311+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:09:35.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:09:35.314+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:09:35.313+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:09:35.943+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:09:35.970+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:09:35.969+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:09:35.992+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:09:35.992+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:09:36.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.706 seconds
[2025-03-10T19:10:06.169+0000] {processor.py:161} INFO - Started process (PID=39) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:10:06.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:10:06.173+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:10:06.173+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:10:06.712+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:10:06.819+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:10:06.819+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:10:06.840+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:10:06.840+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:10:06.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.693 seconds
[2025-03-10T19:10:37.025+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:10:37.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:10:37.028+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:10:37.027+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:10:37.529+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:10:37.553+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:10:37.552+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:10:37.572+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:10:37.572+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:10:37.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.569 seconds
[2025-03-10T19:10:41.053+0000] {processor.py:161} INFO - Started process (PID=43) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:10:41.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:10:41.056+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:10:41.056+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:10:41.982+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:10:42.027+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:10:42.026+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:10:42.066+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:10:42.066+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:10:42.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.054 seconds
[2025-03-10T19:12:20.408+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:12:20.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:12:20.415+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:12:20.414+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:12:22.371+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:12:22.390+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:12:22.390+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:12:22.413+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:12:22.412+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:12:22.430+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 2.037 seconds
[2025-03-10T19:12:52.602+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:12:52.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:12:52.604+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:12:52.604+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:12:53.324+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:12:53.641+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:12:53.641+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:12:53.662+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:12:53.662+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:12:53.681+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.086 seconds
[2025-03-10T19:13:23.777+0000] {processor.py:161} INFO - Started process (PID=37) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:13:23.778+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:13:23.780+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:13:23.779+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:13:24.231+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:13:24.250+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:13:24.249+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:13:24.267+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:13:24.267+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:13:24.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.510 seconds
[2025-03-10T19:13:54.433+0000] {processor.py:161} INFO - Started process (PID=39) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:13:54.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:13:54.436+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:13:54.436+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:13:54.885+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:13:54.903+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:13:54.903+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:13:54.924+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:13:54.923+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:13:54.937+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.509 seconds
[2025-03-10T19:14:25.136+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:14:25.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:14:25.139+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:14:25.139+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:14:25.830+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:14:25.859+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:14:25.858+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:14:25.888+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:14:25.888+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:14:25.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.789 seconds
[2025-03-10T19:14:56.072+0000] {processor.py:161} INFO - Started process (PID=47) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:14:56.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:14:56.075+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:14:56.074+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:14:56.577+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:14:56.597+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:14:56.596+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:14:56.614+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:14:56.613+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:00:00+00:00, run_after=2025-03-10 19:15:00+00:00
[2025-03-10T19:14:56.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.559 seconds
[2025-03-10T19:15:26.764+0000] {processor.py:161} INFO - Started process (PID=57) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:15:26.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:15:26.767+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:15:26.766+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:15:27.264+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:15:27.287+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:15:27.286+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:15:27.309+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:15:27.308+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:15:27.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.577 seconds
[2025-03-10T19:15:29.390+0000] {processor.py:161} INFO - Started process (PID=59) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:15:29.391+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:15:29.392+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:15:29.392+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:15:29.841+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:15:29.859+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:15:29.859+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:15:29.878+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:15:29.878+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:15:29.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.513 seconds
[2025-03-10T19:16:00.059+0000] {processor.py:161} INFO - Started process (PID=65) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:16:00.059+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:16:00.062+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:16:00.061+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:16:00.503+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:16:00.522+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:16:00.521+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:16:00.541+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:16:00.541+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:16:00.554+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.501 seconds
[2025-03-10T19:16:30.715+0000] {processor.py:161} INFO - Started process (PID=67) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:16:30.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:16:30.717+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:16:30.717+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:16:31.204+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:16:31.229+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:16:31.227+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:16:31.250+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:16:31.250+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:16:31.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.556 seconds
[2025-03-10T19:17:01.324+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:17:01.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:17:01.327+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:17:01.326+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:17:01.907+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:17:01.927+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:17:01.926+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:17:01.944+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:17:01.944+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:17:01.959+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.640 seconds
[2025-03-10T19:17:32.149+0000] {processor.py:161} INFO - Started process (PID=71) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:17:32.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:17:32.152+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:17:32.152+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:17:32.644+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:17:32.668+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:17:32.668+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:17:32.689+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:17:32.688+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:17:32.703+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.560 seconds
[2025-03-10T19:18:02.868+0000] {processor.py:161} INFO - Started process (PID=73) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:18:02.870+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:18:02.871+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:18:02.871+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:18:03.381+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:18:03.400+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:18:03.400+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:18:03.419+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:18:03.419+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:18:03.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.574 seconds
[2025-03-10T19:18:33.590+0000] {processor.py:161} INFO - Started process (PID=75) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:18:33.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:18:33.593+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:18:33.593+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:18:34.071+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:18:34.090+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:18:34.090+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:18:34.112+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:18:34.112+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:18:34.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.542 seconds
[2025-03-10T19:19:04.257+0000] {processor.py:161} INFO - Started process (PID=77) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:19:04.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:19:04.259+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:19:04.259+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:19:04.777+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:19:04.801+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:19:04.798+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:19:04.823+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:19:04.823+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:19:04.839+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.588 seconds
[2025-03-10T19:19:35.022+0000] {processor.py:161} INFO - Started process (PID=79) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:19:35.023+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:19:35.025+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:19:35.025+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:19:35.488+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:19:35.509+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:19:35.509+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:19:35.529+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:19:35.529+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:19:35.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.528 seconds
[2025-03-10T19:20:05.703+0000] {processor.py:161} INFO - Started process (PID=81) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:20:05.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:20:05.705+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:20:05.705+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:20:06.192+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:20:06.213+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:20:06.213+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:20:06.233+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:20:06.233+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:20:06.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.550 seconds
[2025-03-10T19:20:36.410+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:20:36.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:20:36.413+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:20:36.413+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:20:36.929+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:20:36.947+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:20:36.947+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:20:36.966+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:20:36.966+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:20:36.985+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.580 seconds
[2025-03-10T19:21:07.148+0000] {processor.py:161} INFO - Started process (PID=85) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:21:07.149+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:21:07.151+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:21:07.150+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:21:07.606+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:21:07.628+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:21:07.627+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:21:07.651+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:21:07.651+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:21:07.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.527 seconds
[2025-03-10T19:21:37.825+0000] {processor.py:161} INFO - Started process (PID=87) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:21:37.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:21:37.828+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:21:37.827+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:21:38.378+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:21:38.407+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:21:38.403+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:21:38.431+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:21:38.431+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:21:38.450+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.630 seconds
[2025-03-10T19:22:08.616+0000] {processor.py:161} INFO - Started process (PID=89) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:22:08.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:22:08.619+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:22:08.619+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:22:09.115+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:22:09.139+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:22:09.139+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:22:09.158+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:22:09.158+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:22:09.173+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.563 seconds
[2025-03-10T19:22:39.339+0000] {processor.py:161} INFO - Started process (PID=91) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:22:39.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:22:39.342+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:22:39.342+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:22:39.834+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:22:39.856+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:22:39.855+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:22:39.875+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:22:39.875+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:22:39.890+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.557 seconds
[2025-03-10T19:23:10.041+0000] {processor.py:161} INFO - Started process (PID=93) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:23:10.042+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:23:10.044+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:23:10.044+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:23:10.542+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:23:10.562+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:23:10.562+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:23:10.584+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:23:10.584+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:23:10.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.564 seconds
[2025-03-10T19:23:40.774+0000] {processor.py:161} INFO - Started process (PID=95) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:23:40.776+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:23:40.778+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:23:40.778+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:23:41.393+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:23:41.415+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:23:41.414+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:23:41.439+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:23:41.438+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:23:41.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.692 seconds
[2025-03-10T19:23:56.255+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:23:56.256+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:23:56.257+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:23:56.257+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:23:56.731+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:23:56.763+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:23:56.762+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:23:56.797+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:23:56.796+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:23:56.825+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.578 seconds
[2025-03-10T19:24:26.992+0000] {processor.py:161} INFO - Started process (PID=103) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:24:26.992+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:24:26.994+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:24:26.994+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:24:27.459+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:24:27.481+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:24:27.480+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:24:27.500+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:24:27.500+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:24:27.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.531 seconds
[2025-03-10T19:24:57.684+0000] {processor.py:161} INFO - Started process (PID=105) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:24:57.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:24:57.686+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:24:57.686+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:24:58.207+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:24:58.229+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:24:58.229+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:24:58.253+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:24:58.253+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:24:58.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.598 seconds
[2025-03-10T19:25:58.408+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:25:58.409+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:25:58.411+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:25:58.411+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:26:00.082+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:26:00.105+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:26:00.104+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:26:00.130+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:26:00.130+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:26:00.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.746 seconds
[2025-03-10T19:26:30.330+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:26:30.331+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:26:30.333+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:26:30.332+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:26:30.960+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:26:31.294+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:26:31.293+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:26:31.313+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:26:31.313+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:26:31.331+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 1.011 seconds
[2025-03-10T19:27:01.487+0000] {processor.py:161} INFO - Started process (PID=33) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:27:01.488+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:27:01.489+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:27:01.489+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:27:01.967+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:27:01.994+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:27:01.993+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:27:02.022+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:27:02.022+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:27:02.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.566 seconds
[2025-03-10T19:27:32.207+0000] {processor.py:161} INFO - Started process (PID=39) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:27:32.208+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:27:32.210+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:27:32.210+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:27:32.734+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:27:32.759+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:27:32.758+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:27:32.788+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:27:32.787+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:27:32.803+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.604 seconds
[2025-03-10T19:28:02.963+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:28:02.963+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:28:02.966+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:28:02.965+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:28:03.487+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:28:03.509+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:28:03.508+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:28:03.531+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:28:03.531+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:28:03.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.591 seconds
[2025-03-10T19:28:33.713+0000] {processor.py:161} INFO - Started process (PID=43) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:28:33.714+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:28:33.715+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:28:33.715+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:28:34.224+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:28:34.247+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:28:34.246+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:28:34.267+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:28:34.267+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:28:34.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.576 seconds
[2025-03-10T19:29:04.450+0000] {processor.py:161} INFO - Started process (PID=45) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:29:04.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:29:04.454+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:29:04.453+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:29:04.996+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:29:05.016+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:29:05.015+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:29:05.035+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:29:05.035+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:29:05.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.610 seconds
[2025-03-10T19:29:13.496+0000] {processor.py:161} INFO - Started process (PID=47) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:29:13.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:29:13.498+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:29:13.498+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:29:13.963+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:29:13.991+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:29:13.990+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:29:14.020+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:29:14.019+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:29:14.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.563 seconds
[2025-03-10T19:29:44.214+0000] {processor.py:161} INFO - Started process (PID=53) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:29:44.215+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:29:44.216+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:29:44.216+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:29:44.675+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:29:44.695+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:29:44.695+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:29:44.716+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:29:44.716+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:15:00+00:00, run_after=2025-03-10 19:30:00+00:00
[2025-03-10T19:29:44.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.523 seconds
[2025-03-10T19:30:14.767+0000] {processor.py:161} INFO - Started process (PID=59) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:30:14.768+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:30:14.770+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:30:14.770+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:30:15.200+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:30:15.219+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:30:15.219+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:30:15.237+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:30:15.237+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:30:15.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.489 seconds
[2025-03-10T19:30:45.451+0000] {processor.py:161} INFO - Started process (PID=61) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:30:45.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:30:45.453+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:30:45.453+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:30:45.885+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:30:45.904+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:30:45.904+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:30:45.922+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:30:45.922+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:30:45.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.489 seconds
[2025-03-10T19:31:16.103+0000] {processor.py:161} INFO - Started process (PID=63) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:31:16.104+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:31:16.106+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:31:16.105+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:31:16.550+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:31:16.569+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:31:16.568+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:31:16.586+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:31:16.586+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:31:16.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.501 seconds
[2025-03-10T19:31:46.786+0000] {processor.py:161} INFO - Started process (PID=65) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:31:46.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:31:46.789+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:31:46.788+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:31:47.221+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:31:47.240+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:31:47.239+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:31:47.257+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:31:47.257+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:31:47.272+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.491 seconds
[2025-03-10T19:32:17.453+0000] {processor.py:161} INFO - Started process (PID=67) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:32:17.454+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:32:17.456+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:32:17.455+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:32:17.896+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:32:17.915+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:32:17.915+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:32:17.937+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:32:17.937+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:32:17.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.505 seconds
[2025-03-10T19:32:48.077+0000] {processor.py:161} INFO - Started process (PID=73) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:32:48.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:32:48.079+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:32:48.079+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:32:48.621+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:32:48.651+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:32:48.650+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:32:48.674+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:32:48.674+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:32:48.691+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.619 seconds
[2025-03-10T19:33:10.837+0000] {processor.py:161} INFO - Started process (PID=75) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:33:10.838+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:33:10.839+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:33:10.839+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:33:11.394+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:33:11.418+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:33:11.417+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:33:11.451+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:33:11.451+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:33:11.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.645 seconds
[2025-03-10T19:33:41.659+0000] {processor.py:161} INFO - Started process (PID=77) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:33:41.660+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:33:41.661+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:33:41.661+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:33:42.141+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:33:42.167+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:33:42.166+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:33:42.194+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:33:42.194+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:33:42.223+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.570 seconds
[2025-03-10T19:33:45.686+0000] {processor.py:161} INFO - Started process (PID=79) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:33:45.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:33:45.688+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:33:45.688+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:33:46.239+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:33:46.272+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:33:46.272+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:33:46.306+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:33:46.306+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:33:46.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.657 seconds
[2025-03-10T19:34:16.426+0000] {processor.py:161} INFO - Started process (PID=81) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:34:16.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:34:16.429+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:34:16.429+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:34:16.888+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:34:16.913+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:34:16.912+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:34:16.932+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:34:16.932+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:34:16.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.525 seconds
[2025-03-10T19:34:47.115+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:34:47.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:34:47.118+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:34:47.117+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:34:47.648+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:34:47.669+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:34:47.667+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:34:47.690+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:34:47.689+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:34:47.704+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.596 seconds
[2025-03-10T19:35:13.768+0000] {processor.py:161} INFO - Started process (PID=85) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:35:13.769+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:35:13.771+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:35:13.770+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:35:14.232+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:35:14.253+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:35:14.252+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:35:14.271+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:35:14.271+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:35:14.287+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.526 seconds
[2025-03-10T19:35:44.436+0000] {processor.py:161} INFO - Started process (PID=87) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:35:44.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:35:44.439+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:35:44.439+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:35:44.934+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:35:44.954+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:35:44.953+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:35:44.974+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:35:44.974+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:35:44.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.559 seconds
[2025-03-10T19:36:15.109+0000] {processor.py:161} INFO - Started process (PID=89) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:36:15.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:36:15.113+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:36:15.112+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:36:15.707+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:36:15.732+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:36:15.732+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:36:15.755+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:36:15.755+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:36:15.775+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.673 seconds
[2025-03-10T19:36:45.952+0000] {processor.py:161} INFO - Started process (PID=91) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:36:45.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:36:45.956+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:36:45.955+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:36:46.534+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:36:46.578+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:36:46.576+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:36:46.623+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:36:46.622+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:36:46.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.705 seconds
[2025-03-10T19:37:16.833+0000] {processor.py:161} INFO - Started process (PID=93) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:37:16.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:37:16.836+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:37:16.835+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:37:17.282+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:37:17.302+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:37:17.301+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:37:17.320+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:37:17.319+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:37:17.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.506 seconds
[2025-03-10T19:37:47.494+0000] {processor.py:161} INFO - Started process (PID=95) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:37:47.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:37:47.497+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:37:47.497+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:37:48.004+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:37:48.024+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:37:48.023+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:37:48.043+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:37:48.043+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:37:48.058+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.571 seconds
[2025-03-10T19:38:18.090+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:38:18.091+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:38:18.092+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:38:18.092+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:38:18.585+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:38:18.604+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:38:18.604+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:38:18.624+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:38:18.624+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:38:18.642+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.558 seconds
[2025-03-10T19:38:48.793+0000] {processor.py:161} INFO - Started process (PID=103) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:38:48.794+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:38:48.796+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:38:48.796+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:38:49.268+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:38:49.293+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:38:49.293+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:38:49.320+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:38:49.320+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:38:49.339+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.551 seconds
[2025-03-10T19:39:19.493+0000] {processor.py:161} INFO - Started process (PID=105) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:39:19.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:39:19.496+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:39:19.496+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:39:19.926+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:39:19.944+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:39:19.944+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:39:19.963+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:39:19.963+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:39:19.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.490 seconds
[2025-03-10T19:39:50.177+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:39:50.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:39:50.180+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:39:50.180+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:39:50.622+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:39:50.641+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:39:50.641+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:39:50.659+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:39:50.659+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:39:50.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.502 seconds
[2025-03-10T19:40:20.860+0000] {processor.py:161} INFO - Started process (PID=109) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:40:20.861+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:40:20.863+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:40:20.863+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:40:21.291+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:40:21.310+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:40:21.310+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:40:21.328+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:40:21.328+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:40:21.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.487 seconds
[2025-03-10T19:40:51.526+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:40:51.527+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:40:51.529+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:40:51.529+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:40:51.951+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:40:51.969+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:40:51.968+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:40:51.986+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:40:51.986+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:40:52.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.481 seconds
[2025-03-10T19:41:22.227+0000] {processor.py:161} INFO - Started process (PID=113) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:41:22.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:41:22.229+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:41:22.229+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:41:22.669+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:41:22.687+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:41:22.686+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:41:22.709+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:41:22.709+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:41:22.725+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.503 seconds
[2025-03-10T19:41:52.914+0000] {processor.py:161} INFO - Started process (PID=115) to work on /opt/airflow/dags/pipeline.py
[2025-03-10T19:41:52.915+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2025-03-10T19:41:52.918+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:41:52.917+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2025-03-10T19:41:53.583+0000] {processor.py:840} INFO - DAG(s) 'sales_pipeline' retrieved from /opt/airflow/dags/pipeline.py
[2025-03-10T19:41:53.633+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:41:53.627+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2025-03-10T19:41:53.667+0000] {logging_mixin.py:188} INFO - [2025-03-10T19:41:53.667+0000] {dag.py:3954} INFO - Setting next_dagrun for sales_pipeline to 2025-03-10 19:30:00+00:00, run_after=2025-03-10 19:45:00+00:00
[2025-03-10T19:41:53.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/pipeline.py took 0.789 seconds
